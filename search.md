# Mini Search Engine in Rust

A full-featured mini search engine implemented in Rust with support for crawling web content, building inverted indexes, TF-IDF ranking, and powerful search APIs.

## ğŸš€ Features

- **ğŸŒ Web Crawling** - Polite web crawling with domain restrictions and configurable delays
- **ğŸ“ Local File Indexing** - Index text files and markdown documents from directories
- **ğŸ” Inverted Index** - Efficient term-to-document mappings with posting lists
- **ğŸ“Š TF-IDF Ranking** - Industry-standard relevance scoring algorithm
- **ğŸ’» CLI Interface** - Command-line tools for indexing and searching
- **ğŸŒ HTTP REST API** - RESTful web service for programmatic access
- **âœ¨ Beautiful Web Frontend** - Modern, responsive search interface
- **ğŸ’¾ Persistent Storage** - Sled embedded database with JSON export option
- **âš¡ Async Support** - High-performance concurrent operations with Tokio

## ğŸ— System Architecture

```
                           Mini Search Engine Architecture
                           â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Web Content   â”‚         â”‚  Local Files    â”‚         â”‚   User Input    â”‚
    â”‚                 â”‚         â”‚                 â”‚         â”‚                 â”‚
    â”‚ -  HTML Pages    â”‚         â”‚ -  Text Files    â”‚         â”‚ -  Search Query  â”‚
    â”‚ -  Articles      â”‚         â”‚ -  Markdown      â”‚         â”‚ -  Index Cmds    â”‚
    â”‚ -  Documentation â”‚         â”‚ -  Documents     â”‚         â”‚                 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                           â”‚                           â”‚
              â–¼                           â–¼                           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Web Crawler    â”‚         â”‚  File Crawler   â”‚         â”‚   User APIs     â”‚
    â”‚                 â”‚         â”‚                 â”‚         â”‚                 â”‚
    â”‚ -  HTTP Requests â”‚         â”‚ -  Directory     â”‚         â”‚ -  CLI Interface â”‚
    â”‚ -  Link Discoveryâ”‚         â”‚   Traversal     â”‚         â”‚ -  HTTP Server   â”‚
    â”‚ -  Content Parse â”‚         â”‚ -  File Reading  â”‚         â”‚ -  Web Frontend  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                           â”‚                           â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
                        â”‚                                             â”‚
                        â–¼                                             â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                     â”‚
              â”‚   Document      â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚   Processing    â”‚
              â”‚                 â”‚
              â”‚ -  Text Extract  â”‚
              â”‚ -  Metadata      â”‚
              â”‚ -  Tokenization  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   Tokenizer     â”‚
              â”‚                 â”‚
              â”‚ -  Word Split    â”‚
              â”‚ -  Normalize     â”‚
              â”‚ -  Stop Words    â”‚
              â”‚ -  Filter Short  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ Inverted Index  â”‚
              â”‚                 â”‚
              â”‚ -  Term -> Docs  â”‚
              â”‚ -  Frequencies   â”‚
              â”‚ -  Posting Lists â”‚
              â”‚ -  Hash Maps     â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ Storage Layer   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”¤   TF-IDF        â”‚
              â”‚                 â”‚         â”‚   Ranker        â”‚
              â”‚ -  Sled Database â”‚         â”‚                 â”‚
              â”‚ -  JSON Files    â”‚         â”‚ -  Score Calc    â”‚
              â”‚ -  Persistence   â”‚         â”‚ -  Relevance     â”‚
              â”‚ -  Serialization â”‚         â”‚ -  Result Sort   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚                           â–²
                        â”‚                           â”‚
                        â–¼                           â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
              â”‚ Search Engine   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                 â”‚
              â”‚ -  Query Process â”‚
              â”‚ -  Index Search  â”‚
              â”‚ -  Result Merge  â”‚
              â”‚ -  Async Ops     â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ Search Results  â”‚
              â”‚                 â”‚
              â”‚ -  Ranked Docs   â”‚
              â”‚ -  Scores        â”‚
              â”‚ -  Snippets      â”‚
              â”‚ -  Metadata      â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

     Data Flow: Content â†’ Crawling â†’ Processing â†’ Indexing â†’ Storage â†’ Search â†’ Results
```

### Architecture Components

#### **Input Layer**
- **Web Content**: HTML pages, articles, documentation from websites
- **Local Files**: Text files, markdown documents from directories
- **User Input**: Search queries and indexing commands via CLI/Web

#### **Crawling Layer**
- **Web Crawler**: Fetches web content with HTTP requests, discovers links, parses HTML
- **File Crawler**: Traverses directories, reads local files, extracts content

#### **Processing Layer**
- **Document Processing**: Extracts text, handles metadata, prepares for tokenization
- **Tokenizer**: Splits text into words, normalizes case, removes stop words, filters short terms

#### **Index Layer**
- **Inverted Index**: Maps terms to documents, tracks frequencies, maintains posting lists using hash maps
- **Storage Layer**: Persists index using Sled database or JSON files with serialization

#### **Search Layer**
- **TF-IDF Ranker**: Calculates relevance scores, ranks results by importance
- **Search Engine**: Processes queries, searches index, merges results, handles async operations

#### **Output Layer**
- **Search Results**: Returns ranked documents with scores, snippets, and metadata

### Key Design Principles

- **Async Processing** - Non-blocking I/O with Tokio runtime
- **Type Safety** - Rust's ownership system prevents memory bugs
- **Modularity** - Clean interfaces between all components
- **Performance** - Efficient data structures and zero-cost abstractions
- **Scalability** - Supports both small and large document collections

## ğŸ“ Project Structure

```
mini-search-engine/
â”œâ”€â”€ Cargo.toml
â”œâ”€â”€ README.md
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.rs           # Main entry point
â”‚   â”œâ”€â”€ lib.rs           # Library exports
â”‚   â”œâ”€â”€ core/            # Core search engine logic
â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â”œâ”€â”€ document.rs   # Document data structures
â”‚   â”‚   â”œâ”€â”€ index.rs     # Inverted index implementation
â”‚   â”‚   â”œâ”€â”€ tokenizer.rs # Text tokenization
â”‚   â”‚   â””â”€â”€ ranking.rs   # TF-IDF ranking algorithm
â”‚   â”œâ”€â”€ crawler/         # Content crawling
â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â”œâ”€â”€ file_crawler.rs
â”‚   â”‚   â””â”€â”€ web_crawler.rs
â”‚   â”œâ”€â”€ storage/         # Persistence layer
â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â”œâ”€â”€ json_storage.rs
â”‚   â”‚   â””â”€â”€ sled_storage.rs
â”‚   â”œâ”€â”€ search/          # Search engine orchestration
â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â””â”€â”€ engine.rs
â”‚   â”œâ”€â”€ api/             # User interfaces
â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â”œâ”€â”€ cli.rs       # Command-line interface
â”‚   â”‚   â””â”€â”€ http.rs      # HTTP server
â”‚   â””â”€â”€ web/             # Web frontend
â”‚       â”œâ”€â”€ mod.rs
â”‚       â””â”€â”€ template.rs  # HTML template
â”œâ”€â”€ data/                # Generated data
â”‚   â”œâ”€â”€ documents/       # Sample documents
â”‚   â””â”€â”€ index/           # Search index storage
â””â”€â”€ examples/            # Usage examples
    â”œâ”€â”€ sample_docs/
    â””â”€â”€ usage.rs
```

## ğŸ›  Getting Started

### Prerequisites

- **Rust** 1.70+ ([Install Rust](https://rustup.rs/))
- **Cargo** (included with Rust)

### Installation

```
cd mini-search-engine
cargo build --release
```

### Quick Start

1. **Index some content:**
```
# Index a website
cargo run -- index-site --url "https://rust-lang.org" --max-pages 5

# Index local files
cargo run -- index --directory examples/sample_docs
```

2. **Search via CLI:**
```
cargo run -- search --query "rust programming" --limit 10
```

3. **Start web server:**
```
cargo run server 3030
```

4. **Open web interface:** [http://localhost:3030](http://localhost:3030)

## ğŸ’» CLI Usage

### Commands

| Command | Description |
|---------|-------------|
| `index --directory <path>` | Index local files |
| `index-site --url <url> --max-pages <n>` | Index website |
| `index-web --urls <url1,url2> --max-pages <n>` | Index specific URLs |
| `search --query <terms> --limit <n>` | Search documents |
| `stats` | Show index statistics |
| `clear` | Clear search index |

### Examples

```
# Index local documentation
cargo run -- index --directory ./docs

# Index Rust documentation
cargo run -- index-site --url "https://doc.rust-lang.org" --max-pages 100

# Search with custom limit
cargo run -- search --query "memory safety ownership" --limit 20

# View index statistics
cargo run -- stats
```

## ğŸŒ HTTP API

Start the web server:
```
cargo run server 3030
```

### Endpoints

| Method | Endpoint | Description | Example |
|--------|----------|-------------|---------|
| `GET` | `/` | Web interface | Browser access |
| `GET` | `/search` | Search documents | `?q=rust&limit=10` |
| `GET` | `/stats` | Index statistics | JSON response |
| `GET` | `/status` | Health check | Server status |
| `POST` | `/index` | Index directory | `{"directory": "/path"}` |
| `POST` | `/index-web` | Index URLs | `{"urls": ["url1"], "max_pages": 50}` |
| `POST` | `/index-site` | Index website | `{"url": "https://site.com", "max_pages": 100}` |

### API Examples

```
# Search via API
curl "http://localhost:3030/search?q=rust%20programming&limit=5"

# Get statistics
curl "http://localhost:3030/stats"

# Index a website
curl -X POST http://localhost:3030/index-site \
  -H "Content-Type: application/json" \
  -d '{"url": "https://rust-lang.org", "max_pages": 10}'
```

### Response Format

```
{
  "query": "rust programming",
  "results": [
    {
      "title": "Rust Programming Language",
      "path": "https://rust-lang.org/",
      "score": 5.9120,
      "snippet": "Rust is a systems programming language..."
    }
  ],
  "total": 1
}
```

## ğŸ¨ Web Interface Features

- **ğŸ” Real-time search** with instant results
- **ğŸ“± Responsive design** for mobile and desktop
- **â­ Relevance scores** visible for each result
- **ğŸ“„ Content snippets** with search term context
- **ğŸ¯ Example queries** for quick testing
- **âš¡ Fast, modern UI** with smooth animations

## ğŸ¯ Key Algorithms

### TF-IDF Scoring

```
score(term, doc) = tf(term, doc) Ã— idf(term)

where:
- tf(term, doc) = 1 + log(frequency)
- idf(term) = log(total_docs / docs_containing_term)
```

### Text Processing

1. **Tokenization** - Split text into words
2. **Normalization** - Convert to lowercase
3. **Stop word removal** - Filter common words
4. **Term filtering** - Remove short terms (<3 chars)

## ğŸ“Š Performance

- **Indexing speed** - ~1000 documents/second
- **Search latency** - Sub-100ms for most queries
- **Memory usage** - Efficient with Rust's zero-cost abstractions
- **Concurrent operations** - Multi-threaded with Tokio

## ğŸ”§ Configuration

### Environment Variables

```
RUST_LOG=debug    # Enable debug logging
DATABASE_PATH=./custom/path    # Custom database location
```

### Crawler Settings

- **Delay between requests** - 1-2 seconds (configurable)
- **Maximum pages per site** - Configurable limit
- **Domain restrictions** - Whitelist/blacklist support
- **Timeout handling** - 30-second request timeout

## ğŸ§ª Testing

```
# Run all tests
cargo test

# Run with output
cargo test -- --nocapture

# Test specific module
cargo test core::index

# Run example
cargo run --example usage
```

## ğŸš€ Deployment

### Production Build

```
cargo build --release
./target/release/search-cli server 8080
```

### Docker Support

```
FROM rust:1.70 as builder
WORKDIR /app
COPY . .
RUN cargo build --release

FROM debian:bookworm-slim
COPY --from=builder /app/target/release/search-cli /usr/local/bin/
EXPOSE 3030
CMD ["search-cli", "server", "3030"]
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## â˜• Support the Project
If you find this project helpful, consider buying me a coffee!
[Buy Me a Coffee](https://buymeacoffee.com/aarambhdevhub)

## ğŸ™ Acknowledgments

- **Rust Community** - For the amazing ecosystem
- **Information Retrieval** - Classic IR algorithms and concepts
- **Modern Search Engines** - Inspiration from Elasticsearch, Solr
- **Web Standards** - HTML5, CSS3, and modern JavaScript

---

**Built with â¤ï¸ and Rust** ğŸ¦€**â¤ï¸ by [Aarambh Dev Hub](https://youtube.com/@aarambhdevhub)**
